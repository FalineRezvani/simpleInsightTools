{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHsoBQkLF+rAXt+To3NdIb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FalineRezvani/simpleInsightTools/blob/main/countBasedLanguageModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count-Based Language Model\n",
        "\n",
        "2025-04-09\n",
        "\n",
        "Count-based language modeling uses conditional probability for word prediction.  This notebook will implement a language model found in The Hundred-Page Language Model Book, by Andriy Burkov, and use data scraped from the GeeksForGeeks website to train the model and make predictions.\n",
        "\n",
        "Language model code and original results can be found in the book [here](https://www.thelmbook.com/).\n",
        "\n",
        "Code for web scraping can be found in my repo [here](https://github.com/FalineRezvani/simpleInsightTools/blob/main/2025-03-20/companyCulture.py)."
      ],
      "metadata": {
        "id": "diUSOiGGam9S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "e2vxZ8hIXH94"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yGWqT8g6Z7Ad"
      },
      "outputs": [],
      "source": [
        "import re # Regular expressions for text processing\n",
        "import math # Python's built-in module for mathematical operations (log, exp)\n",
        "import random # Python's built-in module for random number generation\n",
        "from collections import defaultdict # Efficient dictionary operations\n",
        "import pickle, os # Saving and loading the model\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The set_seed function, from Python's random module ensures reproducibility\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)"
      ],
      "metadata": {
        "id": "Ms3K28jlT-0M"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bringing in CSV File"
      ],
      "metadata": {
        "id": "dBK52go5wJo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDQeokEYwTCs",
        "outputId": "99453c49-f98c-4123-daa8-64f3fb37adc0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading to dataframe the web-scraped data saved to csv file on Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df = pd.read_csv(r'/content/drive/MyDrive/geeksRLDescriptions.csv')\n",
        "\n",
        "# Inspect dataframe\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "lljoMq7mwC8O",
        "outputId": "5f4d6d7d-0498-4f38-da50-f666aa061827"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         description\n",
              "0  Reinforcement learning - GeeksforGeeks\\r\\nSep ...\n",
              "1  Machine Learning Tutorial - GeeksforGeeks\\r\\n5...\n",
              "2  A Beginner's Guide to Deep Reinforcement Learn...\n",
              "3  Upper Confidence Bound Algorithm in Reinforcem...\n",
              "4  On-policy vs off-policy methods Reinforcement ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ad8e545-2360-4ecf-a0d1-a0016a2af63b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Reinforcement learning - GeeksforGeeks\\r\\nSep ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Machine Learning Tutorial - GeeksforGeeks\\r\\n5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A Beginner's Guide to Deep Reinforcement Learn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Upper Confidence Bound Algorithm in Reinforcem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>On-policy vs off-policy methods Reinforcement ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ad8e545-2360-4ecf-a0d1-a0016a2af63b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6ad8e545-2360-4ecf-a0d1-a0016a2af63b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6ad8e545-2360-4ecf-a0d1-a0016a2af63b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b40fb387-497d-4038-a50e-7f6d433eb2ef\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b40fb387-497d-4038-a50e-7f6d433eb2ef')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b40fb387-497d-4038-a50e-7f6d433eb2ef button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Introduction to Machine Learning: What Is and Its Applications ...\\r\\n7 days ago ... Machine learning enables computers to learn from data, identify patterns, and make predictions, driving efficiency and personalization ...\",\n          \"Machine Learning Tutorial - GeeksforGeeks\\r\\n5 days ago ... Machine learning, a subset of Artificial Intelligence, enables computers to learn from data and make predictions through various techniques ...\",\n          \"Multi-armed Bandit Problem in Reinforcement Learning ...\\r\\nJun 18, 2024 ... In the Multi-Armed Bandit problem, an agent is presented with multiple options (arms), each providing a reward drawn from an unknown probability ...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating corpus from dataframe\n",
        "corpus = []\n",
        "\n",
        "for i in range(0, 9):\n",
        "  description = re.compile('<.*?>').sub(repl=' ', string=df.iloc[:,0][i]) # Locating and substituting HTML markup with a space\n",
        "  description = re.compile('[...\\r\\n,-]').sub(' ', description) # Locating and substituting specific symbols with a space\n",
        "  description = description.lower() # Converting to lowercase\n",
        "  corpus.append(description) # Placing in empty list\n",
        "\n",
        "# Creating single string out of list of strings\n",
        "corpus = ''.join(corpus)\n",
        "\n",
        "# Verify\n",
        "corpus[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PtUBeysBwQ6Q",
        "outputId": "fd3a2019-4c69-42f9-bcd5-41b5f96dc61e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'reinforcement learning   geeksforgeeks  sep 4  2024     reinforcement learning (rl) is a branch of m'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing a Count-Based Language Model"
      ],
      "metadata": {
        "id": "WIQjF8NEMGsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CountLanguageModel:\n",
        "  def __init__(self, n):\n",
        "    self.n = n\n",
        "    self.ngram_counts = [{}for _ in range(n)]\n",
        "    self.total_unigrams = 0\n",
        "\n",
        "  def predict_next_token(self, context):\n",
        "    for n in range(self.n, 1, -1):\n",
        "      if len(context) >+ n - 1:\n",
        "        context_n = tuple(context[-(n - 1):])\n",
        "        counts = self.ngram_counts[n - 1].get(context_n)\n",
        "        if counts:\n",
        "          return max(counts.items(), key = lambda x: x[1])[0]\n",
        "    unigram_counts = self.ngram_counts[0].get(())\n",
        "    if unigram_counts:\n",
        "      return max(unigram_counts.items(), key = lambda x: x[1])[0]\n",
        "    return None\n",
        "\n",
        "  def get_probability(self, token, context):\n",
        "      for n in range(self.n, 1, -1):\n",
        "          if len(context) >= n - 1:\n",
        "              context_n = tuple(context[-(n - 1):])\n",
        "              counts = self.ngram_counts[n - 1].get(context_n)\n",
        "              if counts:\n",
        "                  total = sum(counts.values())\n",
        "                  count = counts.get(token, 0)\n",
        "                  if count > 0:\n",
        "                      return count / total\n",
        "      unigram_counts = self.ngram_counts[0].get(())\n",
        "      count = unigram_counts.get(token, 0)\n",
        "      V = len(unigram_counts)\n",
        "      return (count + 1) / (self.total_unigrams + V)"
      ],
      "metadata": {
        "id": "V1WKlT6_aDD-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Methods to Train Model, Generate Text, Compute Perplexity, Tokenize, Download/Pre-Process Data, and Set Hyperparameters."
      ],
      "metadata": {
        "id": "nPgz9AKwL9wR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, tokens):\n",
        "    # Train models for each n-gram size from 1 to n\n",
        "    for n in range(1, model.n + 1):\n",
        "        counts = model.ngram_counts[n - 1]\n",
        "        # Slide a window of size n over the corpus\n",
        "        for i in range(len(tokens) - n + 1):\n",
        "            # Split into context (n-1 tokens) and next token\n",
        "            context = tuple(tokens[i:i + n - 1])\n",
        "            next_token = tokens[i + n - 1]\n",
        "\n",
        "            # Initialize counts dictionary for this context if needed\n",
        "            if context not in counts:\n",
        "                counts[context] = defaultdict(int)\n",
        "\n",
        "            # Increment count for this context-token pair\n",
        "            counts[context][next_token] = counts[context][next_token] + 1\n",
        "\n",
        "    # Store total number of tokens for unigram probability calculations\n",
        "    model.total_unigrams = len(tokens)\n",
        "\n",
        "\n",
        "def generate_text(model, context, num_tokens):\n",
        "    # Start with the provided context\n",
        "    generated = list(context)\n",
        "\n",
        "    # Generate new tokens until we reach the desired length\n",
        "    while len(generated) - len(context) < num_tokens:\n",
        "        # Use the last n-1 tokens as context for prediction\n",
        "        next_token = model.predict_next_token(generated[-(model.n-1):])\n",
        "        generated.append(next_token)\n",
        "\n",
        "        # Stop if we've generated enough tokens AND found a period\n",
        "        # This helps ensure complete sentences\n",
        "        if len(generated) - len(context) >= num_tokens and next_token == '.':\n",
        "            break\n",
        "\n",
        "    # Join tokens with spaces to create readable text\n",
        "    return ' '.join(generated)\n",
        "\n",
        "\n",
        "def compute_perplexity(model, tokens, context_size):\n",
        "    # Handle empty token list\n",
        "    if not tokens:\n",
        "        return float('inf')\n",
        "\n",
        "    # Initialize log likelihood accumulator\n",
        "    total_log_likelihood = 0\n",
        "    num_tokens = len(tokens)\n",
        "\n",
        "    # Calculate probability for each token given its context\n",
        "    for i in range(num_tokens):\n",
        "        # Get appropriate context window, handling start of sequence\n",
        "        context_start = max(0, i - context_size)\n",
        "        context = tuple(tokens[context_start:i])\n",
        "        token = tokens[i]\n",
        "\n",
        "        # Get probability of this token given its context\n",
        "        probability = model.get_probability(token, context)\n",
        "\n",
        "        # Add log probability to total (using log for numerical stability)\n",
        "        total_log_likelihood += math.log(probability)\n",
        "\n",
        "    # Calculate average log likelihood\n",
        "    average_log_likelihood = total_log_likelihood / num_tokens\n",
        "\n",
        "    # Convert to perplexity: exp(-average_log_likelihood)\n",
        "    # Lower perplexity indicates better model performance\n",
        "    perplexity = math.exp(-average_log_likelihood)\n",
        "    return perplexity\n",
        "\n",
        "\n",
        "def tokenize(text):\n",
        "    # Finding letters and periods using the start and end of words and one to the left\n",
        "    return re.findall(r\"\\b[a-zA]+\\b|[.]\", text)\n",
        "\n",
        "\n",
        "def download_and_prepare_data(corpus):\n",
        "    # Convert text to tokens\n",
        "    tokens = tokenize(corpus)\n",
        "\n",
        "    # Split into training (90%) and test (10%) sets\n",
        "    # This reserves data on which to test the models predictions\n",
        "    split_index = int(len(tokens) * 0.9)\n",
        "    train_corpus = tokens[:split_index]\n",
        "    test_corpus = tokens[split_index:]\n",
        "\n",
        "    return train_corpus, test_corpus\n",
        "\n",
        "\n",
        "def get_hyperparameters():\n",
        "    # Size of n-grams to use in the model\n",
        "    n = 5\n",
        "    return n"
      ],
      "metadata": {
        "id": "YHP5DLwYNFBN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving/Loading a Model"
      ],
      "metadata": {
        "id": "KxoaBGnaL2v7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, model_name):\n",
        "    # Create models directory if it doesn't exist\n",
        "    os.makedirs('models', exist_ok=True)\n",
        "\n",
        "    # Construct file path\n",
        "    model_path = os.path.join('models', f'{model_name}.pkl')\n",
        "\n",
        "    try:\n",
        "        print(f\"Saving model to {model_path}...\")\n",
        "        with open(model_path, 'wb') as f:\n",
        "            pickle.dump({\n",
        "                'n': model.n,\n",
        "                'ngram_counts': model.ngram_counts,\n",
        "                'total_unigrams': model.total_unigrams\n",
        "            }, f)\n",
        "        print(\"Model saved successfully.\")\n",
        "        return model_path\n",
        "    except IOError as e:\n",
        "        print(f\"Error saving model: {e}\")\n",
        "        raise\n",
        "\n",
        "def load_model(model_name):\n",
        "    model_path = os.path.join('models', f'{model_name}.pkl')\n",
        "\n",
        "    try:\n",
        "        print(f\"Loading model from {model_path}...\")\n",
        "        with open(model_path, 'rb') as f:\n",
        "            model_data = pickle.load(f)\n",
        "\n",
        "        # Create new model instance\n",
        "        model = CountLanguageModel(model_data['n'])\n",
        "\n",
        "        # Restore model state\n",
        "        model.ngram_counts = model_data['ngram_counts']\n",
        "        model.total_unigrams = model_data['total_unigrams']\n",
        "\n",
        "        print(\"Model loaded successfully.\")\n",
        "        return model\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Model file not found: {model_path}\")\n",
        "        raise\n",
        "    except IOError as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "GeNqqVakL2Ro"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training the Model"
      ],
      "metadata": {
        "id": "jXe9e1LyPxuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main model training block\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize random seeds for reproducibility\n",
        "    set_seed(42)\n",
        "    n = get_hyperparameters()\n",
        "    model_name = \"count_model\"\n",
        "\n",
        "    train_corpus, test_corpus = download_and_prepare_data(corpus)\n",
        "\n",
        "    # Train the model and evaluate its performance\n",
        "    print(\"\\nTraining the model...\")\n",
        "    model = CountLanguageModel(n)\n",
        "    train(model, train_corpus)\n",
        "    print(\"\\nModel training complete.\")\n",
        "\n",
        "    perplexity = compute_perplexity(model, test_corpus, n)\n",
        "    print(f\"\\nPerplexity on test corpus: {perplexity:.2f}\")\n",
        "\n",
        "    save_model(model, model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eon0pplXONXP",
        "outputId": "cce27c85-ea3e-4888-b1fd-cb020cfb1211"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training the model...\n",
            "\n",
            "Model training complete.\n",
            "\n",
            "Perplexity on test corpus: 21.19\n",
            "Saving model to models/count_model.pkl...\n",
            "Model saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output of the model training shows us the __perplexity__, which measures how \"sure\" the model is about its choice of next word (token). A higher number means the model is picking one out of that number of tokens as its choice.  A lower number suggests a more \"sure\" choice."
      ],
      "metadata": {
        "id": "uBFQ4PfoTJej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing the Model"
      ],
      "metadata": {
        "id": "F527KVjKWM_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main model testing block\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    model = load_model(model_name)\n",
        "\n",
        "    # These contexts gives the model a chance to finish sentences\n",
        "    contexts = [\n",
        "        \"i will build a\",\n",
        "        \"the best place to\",\n",
        "        \"she was riding a\"\n",
        "    ]\n",
        "\n",
        "    # Generate completions for each context\n",
        "    for context in contexts:\n",
        "        tokens = tokenize(context)\n",
        "        next_token = model.predict_next_token(tokens)\n",
        "        print(f\"\\nContext: {context}\")\n",
        "        print(f\"Next token: {next_token}\")\n",
        "        print(f\"Generated text: {generate_text(model, tokens, 10)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDNjKSFnV5-p",
        "outputId": "3577eaba-4222-49ac-bf92-8ed7962bc541"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from models/count_model.pkl...\n",
            "Model loaded successfully.\n",
            "\n",
            "Context: i will build a\n",
            "Next token: branch\n",
            "Generated text: i will build a branch of machine learning focused on making decisions to maximize\n",
            "\n",
            "Context: the best place to\n",
            "Next token: maximize\n",
            "Generated text: the best place to maximize cumulative rewards in a given situation machine learning tutorial\n",
            "\n",
            "Context: she was riding a\n",
            "Next token: branch\n",
            "Generated text: she was riding a branch of machine learning focused on making decisions to maximize\n"
          ]
        }
      ]
    }
  ]
}